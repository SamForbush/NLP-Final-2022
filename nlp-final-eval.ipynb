{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Dense, LSTM, Embedding\nimport matplotlib.pyplot as plt \nimport nltk\nfrom nltk.tokenize import word_tokenize\nimport re","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-12-05T03:47:49.472057Z","iopub.execute_input":"2022-12-05T03:47:49.472897Z","iopub.status.idle":"2022-12-05T03:47:56.006830Z","shell.execute_reply.started":"2022-12-05T03:47:49.472779Z","shell.execute_reply":"2022-12-05T03:47:56.005342Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install pronouncing\n!pip install cmudict\nimport cmudict\nimport pronouncing","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:47:56.012827Z","iopub.execute_input":"2022-12-05T03:47:56.013557Z","iopub.status.idle":"2022-12-05T03:48:16.112784Z","shell.execute_reply.started":"2022-12-05T03:47:56.013514Z","shell.execute_reply":"2022-12-05T03:48:16.111628Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: pronouncing in /opt/conda/lib/python3.7/site-packages (0.2.0)\nRequirement already satisfied: cmudict>=0.4.0 in /opt/conda/lib/python3.7/site-packages (from pronouncing) (1.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: cmudict in /opt/conda/lib/python3.7/site-packages (1.0.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('punkt')\n\n# check if token is a punctuation marker\ndef is_punct(token):\n  for c in token:\n    if c.isalpha(): return False\n  return True\n\n# remove punctuation and set to lowercase for list of tokens\ndef clean(tokens):\n  return [token.lower() for token in tokens if not is_punct(token)]\n\n# tokenize poem in file\ndef file_to_tokens(filepath):\n  # read in poem from file\n  with open(filepath, 'r') as fp:\n    poem_lines = fp.readlines()\n\n  if len(poem_lines) < 4: return 0\n\n  # remove byte order marker\n  if ord(poem_lines[0][0]) == 65279:\n    poem_lines[0] = poem_lines[0][1:]\n\n  # tokenize each line\n  return [clean(nltk.tokenize.word_tokenize(line)) for line in poem_lines]\n\n# tokenize list of lines\ndef lines_to_tokens(lines):\n  if ord(lines[0][0]) == 65279:\n    lines[0] = lines[0][1:]\n  return [clean(nltk.tokenize.word_tokenize(line)) for line in lines]","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:16.114715Z","iopub.execute_input":"2022-12-05T03:48:16.116193Z","iopub.status.idle":"2022-12-05T03:48:16.318443Z","shell.execute_reply.started":"2022-12-05T03:48:16.116153Z","shell.execute_reply":"2022-12-05T03:48:16.317301Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install wordfreq\nimport wordfreq\nfrom math import log\n\n# given a word, return its log frequency\ndef get_freq(word):\n  freq = wordfreq.word_frequency(word, 'en')\n  if freq <= 0: return 0\n  return log(freq)\n\n# get avg log frequency\ndef get_log_freq(toklines):\n  # sum up log frequencies of all words in the poem\n  total_freq = 0\n  word_count = 0\n  for line in toklines:\n    for word in line:\n      total_freq += get_freq(word.lower())\n      word_count += 1\n\n  # compute average log frequency and word count\n  return (total_freq / word_count, word_count)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:16.321325Z","iopub.execute_input":"2022-12-05T03:48:16.322095Z","iopub.status.idle":"2022-12-05T03:48:28.524496Z","shell.execute_reply.started":"2022-12-05T03:48:16.322065Z","shell.execute_reply":"2022-12-05T03:48:28.523484Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting wordfreq\n  Downloading wordfreq-3.0.3-py3-none-any.whl (56.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: regex>=2021.7.6 in /opt/conda/lib/python3.7/site-packages (from wordfreq) (2021.11.10)\nRequirement already satisfied: langcodes>=3.0 in /opt/conda/lib/python3.7/site-packages (from wordfreq) (3.3.0)\nCollecting ftfy>=6.1\n  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: msgpack>=1.0 in /opt/conda/lib/python3.7/site-packages (from wordfreq) (1.0.4)\nRequirement already satisfied: wcwidth>=0.2.5 in /opt/conda/lib/python3.7/site-packages (from ftfy>=6.1->wordfreq) (0.2.5)\nInstalling collected packages: ftfy, wordfreq\nSuccessfully installed ftfy-6.1.1 wordfreq-3.0.3\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"# for every poem, obtain a set of unique words; merge all the sets\nimport functools\n\n# get type-token ratio\ndef get_tt_ratio(toklines, word_count):\n  types = functools.reduce(lambda x, y : set(x).union(set(y)), toklines)\n\n  # compute type-token ratio\n  return len(types) / word_count","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.526407Z","iopub.execute_input":"2022-12-05T03:48:28.526761Z","iopub.status.idle":"2022-12-05T03:48:28.535338Z","shell.execute_reply.started":"2022-12-05T03:48:28.526725Z","shell.execute_reply":"2022-12-05T03:48:28.533429Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## preprocessing stuff\ndef preprocess():\n  # get words as phonemes\n  phoneme_dict = cmudict.dict()\n\n  # get vowels\n  # 1: vowel, 0: consonant\n  vowel_dict = dict()\n  for phone, group in cmudict.phones():\n    vowel_dict[phone] = int(group[0] == 'vowel')\n  return phoneme_dict, vowel_dict","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.538028Z","iopub.execute_input":"2022-12-05T03:48:28.538401Z","iopub.status.idle":"2022-12-05T03:48:28.568234Z","shell.execute_reply.started":"2022-12-05T03:48:28.538362Z","shell.execute_reply":"2022-12-05T03:48:28.567089Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## helper functions\n\n# given a word, return the most common pronunciation\ndef get_phonemes(word, phoneme_dict):\n  pronunciations = phoneme_dict[word]\n  if len(pronunciations) == 0: return []\n  return pronunciations[0]\n\n# given a sequence of phonemes, return the index of the stressed vowel\n# if no stressed syllable (e.g. 'a'), return 0\ndef get_stress_idx(pron):\n  for idx, val in enumerate(pron):\n    if val[-1] == '1': return idx\n  return 0\n\n# given a sequence of phonemes, return the onset if it exists\n# otherwise, return the stressed vowel\ndef get_onset(pron):\n  stress_idx = get_stress_idx(pron)\n  if stress_idx == 0: return pron[0]\n  return pron[stress_idx - 1]\n\n# given a sequence of phonemes, return the rime (part of a syllable; not rhyme)\ndef get_rime(pron):\n  stress_idx = get_stress_idx(pron)\n  return pron[stress_idx:]\n\n# given two lines, determine whether they form a perfect rhyme\ndef is_perfect(a, b, phoneme_dict):\n  # get phoneme representations of last two words\n  pron_a = get_phonemes(a[-1], phoneme_dict)\n  pron_b = get_phonemes(b[-1], phoneme_dict)\n\n  # known word check\n  if len(pron_a) == 0 or len(pron_b) == 0: return False\n\n  # onset check\n  onset_a = get_onset(pron_a)\n  onset_b = get_onset(pron_b)\n  if onset_a == onset_b: return False\n\n  # rime check\n  rime_a = get_rime(pron_a)\n  rime_b = get_rime(pron_b)\n  if len(rime_a) != len(rime_b): return False\n  for p_a, p_b in zip(rime_a, rime_b):\n    if p_a != p_b: return False\n  \n  # all checks passed\n  return True\n\n# given two lines, count the number of slant rhymes\ndef is_slant(a, b, phoneme_dict):\n  # get phoneme representations of last two words\n  pron_a = get_phonemes(a[-1], phoneme_dict)\n  pron_b = get_phonemes(b[-1], phoneme_dict)\n\n  # known word check\n  if len(pron_a) == 0 or len(pron_b) == 0: return False\n\n  # stressed vowel check\n  rime_a = get_rime(pron_a)\n  rime_b = get_rime(pron_b)\n  if rime_a[0] != rime_b[0]: return False\n\n  # rime check\n  if len(rime_a) != len(rime_b): return True\n  for p_a, p_b in zip(rime_a, rime_b):\n    if p_a != p_b: return True\n  \n  # rime check failed\n  return False\n\n# given a window of up to four lines, count the number of perfect and slant rhymes\nfrom itertools import combinations\ndef count_rhymes_window(lines, phoneme_dict):\n  perf, slant = 0, 0\n  pairs = list(combinations(lines, 2))\n  for a, b in pairs:\n    if len(a) == 0 or len(b) == 0: continue\n    if is_perfect(a, b, phoneme_dict):\n      perf += 1\n    if is_slant(a, b, phoneme_dict):\n      slant += 1\n  return perf, slant\n\n# given all lines of a poem, count the number of perfect and slant rhymes\ndef count_rhymes(lines, phoneme_dict):\n  perf, slant = 0, 0\n\n  # for short poems, use a single window\n  if len(lines) < 5: return count_rhymes_window(lines, phoneme_dict)\n\n  # check all 4-line windows\n  num_windows, last_window_len = divmod(len(lines), 4)\n  for idx in range(num_windows):\n    start = 4 * idx\n    end = 4 * idx + 4\n    new_perf, new_slant = count_rhymes_window(lines[start:end], phoneme_dict)\n    perf += new_perf\n    slant += new_slant\n  \n  # last window check\n  if last_window_len > 0:\n    new_perf, new_slant = count_rhymes_window(lines[4 * num_windows:], phoneme_dict)\n    perf += new_perf\n    slant += new_slant\n  \n  # output normalized counts\n  return perf, slant","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.569795Z","iopub.execute_input":"2022-12-05T03:48:28.570413Z","iopub.status.idle":"2022-12-05T03:48:28.587830Z","shell.execute_reply.started":"2022-12-05T03:48:28.570375Z","shell.execute_reply":"2022-12-05T03:48:28.586911Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"def get_rhyme_counts(toklines, word_count, phoneme_dict):\n  perf, slant = count_rhymes(toklines, phoneme_dict)\n  perf_freq, slant_freq = perf / word_count, slant / word_count\n  return perf_freq, slant_freq","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.589120Z","iopub.execute_input":"2022-12-05T03:48:28.590020Z","iopub.status.idle":"2022-12-05T03:48:28.600870Z","shell.execute_reply.started":"2022-12-05T03:48:28.589986Z","shell.execute_reply":"2022-12-05T03:48:28.599970Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# get initial consonant of a word\ndef get_initial(word, phoneme_dict):\n  phonemes = phoneme_dict[word]\n  if len(phonemes) == 0: return ''\n  return phonemes[0][0]\n\n# count instances of alliteration\ndef count_alliteration(lines, word_count, phoneme_dict):\n  count = 0\n  for line in lines:\n    for idx in range(len(line) - 1):\n      if get_initial(line[idx], phoneme_dict) == get_initial(line[idx + 1], phoneme_dict): count += 1\n  \n  # output normalized count\n  return count / word_count","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.602177Z","iopub.execute_input":"2022-12-05T03:48:28.602636Z","iopub.status.idle":"2022-12-05T03:48:28.611834Z","shell.execute_reply.started":"2022-12-05T03:48:28.602542Z","shell.execute_reply":"2022-12-05T03:48:28.610733Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from nltk.sentiment import SentimentIntensityAnalyzer\nnltk.download('vader_lexicon')\n\n# compute sentiment\ndef get_pos_neg(toklines, word_count):\n  sia = SentimentIntensityAnalyzer()\n  pos, neg = 0, 0\n\n  for line in toklines:\n    for word in line:\n      #print(word, sia.polarity_scores(word))\n      polarity = sia.polarity_scores(word)\n      if polarity['pos'] > 0: pos += 1\n      if polarity['neg'] > 0: neg += 1\n\n  # normalize counts\n  pos = pos / word_count\n  neg = neg / word_count\n  return pos, neg","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.613336Z","iopub.execute_input":"2022-12-05T03:48:28.613749Z","iopub.status.idle":"2022-12-05T03:48:28.633347Z","shell.execute_reply.started":"2022-12-05T03:48:28.613715Z","shell.execute_reply":"2022-12-05T03:48:28.632092Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"}]},{"cell_type":"code","source":"# compute concreteness, abstractness, generalization scores\ndef compute_cag(toklines, word_count):\n  concrete_words = {'tree', 'room', 'thing', 'grass', 'wall',\n            'flower', 'glass', 'floor', 'dirt', 'car'}\n  abstract_words = {'day', 'night', 'year', 'time', 'death',\n              'new', 'morning', 'childhood', 'hour', 'afternoon'}\n  general_words = {'all', 'nothing', 'never', 'always', 'every',\n            'any', 'anything', 'nobody', 'everything', 'forever'}\n  concrete, abstract, general = 0, 0, 0\n  for line in toklines:\n    for word in line:\n      if word in concrete_words: concrete += 1\n      if word in abstract_words: abstract += 1\n      if word in general_words: general += 1\n\n  # normalize counts\n  concrete = concrete / word_count\n  abstract = abstract / word_count\n  general = general / word_count\n  return concrete, abstract, general","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.637303Z","iopub.execute_input":"2022-12-05T03:48:28.637561Z","iopub.status.idle":"2022-12-05T03:48:28.644079Z","shell.execute_reply.started":"2022-12-05T03:48:28.637538Z","shell.execute_reply":"2022-12-05T03:48:28.642901Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"def evaluate(toklines):\n  # compute desired features\n  avg_freq, word_count = get_log_freq(toklines)\n  tt_ratio = get_tt_ratio(toklines, word_count)\n  phoneme_dict, vowel_dict = preprocess()\n  perf_freq, slant_freq = get_rhyme_counts(toklines, word_count, phoneme_dict)\n  allit = count_alliteration(toklines, word_count, phoneme_dict)\n  pos, neg = get_pos_neg(toklines, word_count)\n  concrete, abstract, general = compute_cag(toklines, word_count)\n\n  # coalesce weights and features\n  eval_weights = [-0.5039, 0.6646, 0.4602, -2.1, -0.6326,\n                  -1.0701, -0.7861, 1.3124, -1.2633, -0.836]\n  eval_features = [avg_freq, tt_ratio, perf_freq, slant_freq, allit,\n                  pos, neg, concrete, abstract, general]\n\n  # dot product of scores and weights\n  eval_score = 0\n  for weight, feature in zip(eval_weights, eval_features):\n    eval_score += weight * feature\n  return eval_score\n\ndef evaluate_file(filepath):\n  toklines = file_to_tokens(filepath)\n  return evaluate(toklines)\n\ndef evaluate_poem(lines):\n  return evaluate(lines)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.645804Z","iopub.execute_input":"2022-12-05T03:48:28.646209Z","iopub.status.idle":"2022-12-05T03:48:28.657475Z","shell.execute_reply.started":"2022-12-05T03:48:28.646176Z","shell.execute_reply":"2022-12-05T03:48:28.656425Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model = keras.models.load_model('../input/largemodelv3/large_set_model_v3.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:28.658915Z","iopub.execute_input":"2022-12-05T03:48:28.659304Z","iopub.status.idle":"2022-12-05T03:48:33.356235Z","shell.execute_reply.started":"2022-12-05T03:48:28.659263Z","shell.execute_reply":"2022-12-05T03:48:33.355059Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stderr","text":"2022-12-05 03:48:29.147636: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:29.250519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:29.251336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:29.253428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-12-05 03:48:29.253743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:29.254471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:29.255137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:31.344899: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:31.345715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:31.346427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n2022-12-05 03:48:31.347034: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"}]},{"cell_type":"code","source":"vocabulary = ['\\n', ' ', '!', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '?', 'a',\n 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's',\n 't', 'u', 'v', 'w', 'x', 'y', 'z']","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:33.357807Z","iopub.execute_input":"2022-12-05T03:48:33.358182Z","iopub.status.idle":"2022-12-05T03:48:33.369629Z","shell.execute_reply.started":"2022-12-05T03:48:33.358145Z","shell.execute_reply":"2022-12-05T03:48:33.365921Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"tokenizer = {'\\n': 0, ' ': 1, '!': 2, ',': 3, '-': 4, '.': 5, '0': 6, '1': 7, '2': 8, '3': 9, '4': 10, '5': 11, '6': 12, '7': 13, '8': 14, '9': 15, '?': 16, 'a': 17, 'b': 18, 'c': 19, 'd': 20, 'e': 21, 'f': 22, 'g': 23, 'h': 24, 'i': 25, 'j': 26, 'k': 27, 'l': 28, 'm': 29, 'n': 30, 'o': 31, 'p': 32, 'q': 33, 'r': 34, 's': 35, 't': 36, 'u': 37, 'v': 38, 'w': 39, 'x': 40, 'y': 41, 'z': 42}","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:48:33.371090Z","iopub.execute_input":"2022-12-05T03:48:33.372096Z","iopub.status.idle":"2022-12-05T03:48:33.385791Z","shell.execute_reply.started":"2022-12-05T03:48:33.372050Z","shell.execute_reply":"2022-12-05T03:48:33.384791Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"sample = \"I \"\n # vectorize the string\nsample = sample.lower()\n#count existing syllables\nsample_vector = [tokenizer[char] for char in sample]\npredicted = sample_vector\n # convert into tensor of required dimensions\nsample_tensor = tf.expand_dims(sample_vector, 0) \n # broadcast to first dimension to 64 \nsample_tensor = tf.repeat(sample_tensor, 64, axis=0)\n\n # temperature is a sensitive variable to adjust prediction\ntemperature = .95\npoem = sample\nchar_counter = 0\npoem_counter = 0\nmax_poems = 10\nbest_poem = \"\"\nbest_eval = -100\ntot_eval = 0\n\nwhile poem_counter < max_poems:\n     pred = model(sample_tensor)\n     pred = pred[0].numpy()/temperature\n     pred = tf.random.categorical(pred, num_samples=1)[-1,0].numpy()\n     if pred == 0 and char_counter > 500:\n        curr_eval = evaluate(poem)\n        print(curr_eval)\n        tot_eval += curr_eval\n        poem = sample\n        poem_counter += 1\n        char_counter = 0\n        sample_vector = [tokenizer[char] for char in sample]\n        sample_tensor = tf.expand_dims(sample_vector, 0) \n        sample_tensor = tf.repeat(sample_tensor, 64, axis=0)\n     else:\n       guess = vocabulary[pred]\n       poem += guess\n       char_counter += 1\n       predicted.append(pred)\n       sample_tensor = predicted[-199:]\n       sample_tensor = tf.expand_dims([pred],0) \n       sample_tensor = tf.repeat(sample_tensor, 64, axis=0)\n\nprint(tot_eval/max_poems)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:08:49.727951Z","iopub.execute_input":"2022-12-05T04:08:49.728316Z","iopub.status.idle":"2022-12-05T04:09:50.376632Z","shell.execute_reply.started":"2022-12-05T04:08:49.728286Z","shell.execute_reply":"2022-12-05T04:09:50.375561Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"2.949472836000669\n2.860654322042549\n2.8722246116917503\n2.956060900491604\n2.993438865516859\n3.0610442743630086\n2.92537967716342\n2.897661185867009\n2.9307046499560077\n2.9231281990210896\n2.9369769522113964\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nf = pd.read_csv(\"../input/poetry-foundation-poems/PoetryFoundationData.csv\")\n#f2 = pd.read_csv(\"StylusPoems2017-2022.csv\")\nprint(len(f))","metadata":{"execution":{"iopub.status.busy":"2022-12-05T03:56:55.663197Z","iopub.execute_input":"2022-12-05T03:56:55.663552Z","iopub.status.idle":"2022-12-05T03:56:56.250190Z","shell.execute_reply.started":"2022-12-05T03:56:55.663520Z","shell.execute_reply":"2022-12-05T03:56:56.249256Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"13854\n","output_type":"stream"}]},{"cell_type":"code","source":"nltk.download('punkt')\ntxt_batches = f['Poem'].values\n\nfor i,p in enumerate(txt_batches):\n  s = txt_batches[i]\n  s = s.replace(\"\\n\", \" \\n \")\n  s = re.sub('—', '-', s)\n  s = re.sub('[^A-Za-z0-9\\n,. !?-]+', '', s)\n  s = re.sub('\\b\\b+', ' ', s)\n  s = s.lower()\n  s = s.split(\"\\n\")\n  temp = [\"\"]\n  temp = np.array(temp)\n  for sent in s:\n    temp = np.append(temp, np.array(word_tokenize(sent)))\n    temp = np.append(temp, \"\\n\")\n  s = temp\n  txt_batches[i] = s[1:]\n\nprint(txt_batches[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:05:05.632316Z","iopub.execute_input":"2022-12-05T04:05:05.632826Z","iopub.status.idle":"2022-12-05T04:06:02.213663Z","shell.execute_reply.started":"2022-12-05T04:05:05.632794Z","shell.execute_reply":"2022-12-05T04:06:02.212609Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stdout","text":"['\\n' 'the' 'old' 'cupola' 'glinted' 'above' 'the' 'clouds' ',' 'shone'\n '\\n' 'among' 'fir' 'trees' ',' 'but' 'it' 'took' 'him' 'an' 'hour' '\\n'\n 'for' 'the' 'half' 'mile' 'all' 'the' 'way' 'up' 'the' 'hill' '.' 'as'\n 'he' 'trailed' ',' '\\n' 'the' 'village' 'passed' 'him' 'by' ',' 'greeted'\n 'him' ',' '\\n' 'asked' 'about' 'his' 'health' ',' 'but' 'everybody'\n 'hurried' '\\n' 'to' 'catch' 'the' 'mass' ',' 'left' 'him' 'leaning'\n 'against' 'fences' ',' '\\n' 'measuring' 'the' 'road' 'with' 'the'\n 'walking' 'stick' 'he' 'sculpted' '.' '\\n' 'he' 'yearned' 'for' 'the'\n 'day' 'when' 'the' 'new' 'church' '\\n' 'would' 'be' 'built-right'\n 'across' 'the' 'road' '.' 'now' '\\n' 'it' 'rises' 'above' 'the' 'moon'\n 'saints' 'in' 'frescoes' '\\n' 'meet' 'the' 'eye' ',' 'and' 'only' 'the'\n 'rain' 'has' 'started' 'to' 'cut' '\\n' 'through' 'the' 'shingles' 'on'\n 'the' 'roof' 'of' 'his' 'empty' '\\n' 'house' '.' 'the' 'apple' 'trees'\n 'have' 'taken' 'over' 'the' 'sky' ',' '\\n' 'sequestered' 'the' 'gate' ','\n 'sidled' 'over' 'the' 'porch' '.' '\\n' '\\n']\n","output_type":"stream"}]},{"cell_type":"code","source":"text = []\nprint(len(txt_batches))\n\n\nfor b in txt_batches:\n    text.append(\" \".join(b))\n    \nprint(text[1])","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:07:05.350549Z","iopub.execute_input":"2022-12-05T04:07:05.350924Z","iopub.status.idle":"2022-12-05T04:07:06.903698Z","shell.execute_reply.started":"2022-12-05T04:07:05.350890Z","shell.execute_reply":"2022-12-05T04:07:06.902660Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"13854\n\n the old cupola glinted above the clouds , shone \n among fir trees , but it took him an hour \n for the half mile all the way up the hill . as he trailed , \n the village passed him by , greeted him , \n asked about his health , but everybody hurried \n to catch the mass , left him leaning against fences , \n measuring the road with the walking stick he sculpted . \n he yearned for the day when the new church \n would be built-right across the road . now \n it rises above the moon saints in frescoes \n meet the eye , and only the rain has started to cut \n through the shingles on the roof of his empty \n house . the apple trees have taken over the sky , \n sequestered the gate , sidled over the porch . \n \n\n","output_type":"stream"}]},{"cell_type":"code","source":"tot_eval = 0\nfor p in text[20:40]:\n    curr_eval = curr_eval = evaluate(p[:200])\n    print(curr_eval)\n    tot_eval+=curr_eval\n\nprint(tot_eval/20)","metadata":{"execution":{"iopub.status.busy":"2022-12-05T04:12:04.962023Z","iopub.execute_input":"2022-12-05T04:12:04.962746Z","iopub.status.idle":"2022-12-05T04:12:26.641314Z","shell.execute_reply.started":"2022-12-05T04:12:04.962703Z","shell.execute_reply":"2022-12-05T04:12:26.640271Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"2.766384367089158\n3.110730611622347\n2.800026116498493\n3.0635738883632855\n2.6983208369961535\n3.1416161908440485\n2.7743114602590335\n2.734356581539228\n2.88971885798861\n3.126142669205732\n2.81526025115887\n2.990900378211726\n3.0126146736098494\n2.9607866773995113\n2.980943770629999\n3.067947725596454\n3.2547011568345385\n3.25323564916435\n2.96721057597221\n2.851758723672021\n2.9630270581327807\n","output_type":"stream"}]}]}